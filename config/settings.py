"""
ãƒãƒ«ãƒãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆå¯¾å¿œæ±ç”¨RAGã‚·ã‚¹ãƒ†ãƒ  - è¨­å®šç®¡ç†

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã®è¨­å®šã‚’ç®¡ç†ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ã€ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®šã‚’è¡Œã†
Google Cloud E2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¯¾å¿œã€qwen2:7bæœ€é©åŒ–
"""

import os
import logging
from pathlib import Path
from typing import List, Optional
from pydantic import Field, field_validator
from pydantic_settings import BaseSettings
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

class Settings(BaseSettings):
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã‚¯ãƒ©ã‚¹"""
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºæœ¬è¨­å®š
    project_name: str = "ãƒãƒ«ãƒãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆå¯¾å¿œæ±ç”¨RAGã‚·ã‚¹ãƒ†ãƒ "
    version: str = "0.1.0"
    environment: str = Field(default="development", env="ENVIRONMENT")
    
    # Ollama LLMè¨­å®šï¼ˆqwen2:7b - 8GB RAMæœ€é©åŒ–ï¼‰
    ollama_host: str = Field(default="127.0.0.1:11434", env="OLLAMA_HOST")
    llm_model_name: str = Field(default="qwen2:7b", env="LLM_MODEL_NAME")
    ollama_timeout: int = Field(default=300, env="OLLAMA_TIMEOUT")
    max_concurrent_requests: int = Field(default=10, env="MAX_CONCURRENT_REQUESTS")
    
    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢è¨­å®šï¼ˆãƒãƒ«ãƒãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆå¯¾å¿œï¼‰
    data_dir: str = Field(default="./data", env="DATA_DIR")
    embedding_model: str = Field(default="all-MiniLM-L6-v2", env="EMBEDDING_MODEL")
    persist_directory: str = Field(default="./data/vectorstore", env="PERSIST_DIRECTORY")
    
    # FastAPIè¨­å®š
    server_host: str = Field(default="127.0.0.1", env="SERVER_HOST")
    server_port: int = Field(default=8000, env="SERVER_PORT")
    cors_origins: List[str] = Field(default=["*"], env="CORS_ORIGINS")
    max_chatbots: int = Field(default=5, env="MAX_CHATBOTS")
    
    # ãƒ­ã‚°è¨­å®š
    log_level: str = Field(default="INFO", env="LOG_LEVEL")
    log_dir: str = Field(default="./logs", env="LOG_DIR")
    
    # RAGè¨­å®š
    chunk_size: int = Field(default=1000, env="CHUNK_SIZE")
    chunk_overlap: int = Field(default=200, env="CHUNK_OVERLAP")
    similarity_search_k: int = Field(default=3, env="SIMILARITY_SEARCH_K")
    max_tokens: int = Field(default=4000, env="MAX_TOKENS")
    
    # UIè¨­å®šï¼ˆiframeåŸ‹ã‚è¾¼ã¿å¯¾å¿œï¼‰
    enable_file_upload: bool = Field(default=True, env="ENABLE_FILE_UPLOAD")
    max_file_size_mb: int = Field(default=10, env="MAX_FILE_SIZE_MB")
    supported_file_types: List[str] = Field(default=["pdf", "md", "txt", "docx"])
    enable_iframe_embed: bool = Field(default=True, env="ENABLE_IFRAME_EMBED")
    allowed_embed_domains: List[str] = Field(default=["*"], env="ALLOWED_EMBED_DOMAINS")
    
    # ãƒ‡ãƒãƒƒã‚°è¨­å®š
    langchain_tracing_v2: bool = Field(default=False)
    ollama_debug: bool = Field(default=False)
    
    # LangSmithè¨­å®š
    langsmith_api_key: Optional[str] = Field(default=None, env="LANGSMITH_API_KEY")
    langsmith_project: str = Field(default="labor-chatbot-rag", env="LANGSMITH_PROJECT")
    langsmith_endpoint: str = Field(default="https://api.smith.langchain.com", env="LANGSMITH_ENDPOINT")
    enable_langsmith: bool = Field(default=False, env="ENABLE_LANGSMITH")
    
    @field_validator("supported_file_types", mode="before")
    @classmethod
    def parse_file_types(cls, v):
        """ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ãƒ‘ãƒ¼ã‚¹"""
        if isinstance(v, str):
            return [ext.strip() for ext in v.split(",")]
        return v
    
    @field_validator("cors_origins", mode="before")
    @classmethod
    def parse_cors_origins(cls, v):
        """CORSè¨­å®šã‚’ãƒ‘ãƒ¼ã‚¹"""
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(",")]
        return v
    
    @field_validator("allowed_embed_domains", mode="before")
    @classmethod
    def parse_embed_domains(cls, v):
        """åŸ‹ã‚è¾¼ã¿è¨±å¯ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ãƒ‘ãƒ¼ã‚¹"""
        if isinstance(v, str):
            return [domain.strip() for domain in v.split(",")]
        return v
    
    @field_validator("log_level")
    @classmethod
    def validate_log_level(cls, v):
        """ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
        valid_levels = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
        if v.upper() not in valid_levels:
            raise ValueError(f"ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã¯ {valid_levels} ã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        return v.upper()
    
    def setup_logging(self) -> None:
        """ãƒ­ã‚°è¨­å®šã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        log_path = Path(self.log_dir)
        log_path.mkdir(parents=True, exist_ok=True)
        
        # ãƒ­ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®è¨­å®š
        log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        log_file = log_path / "labor_qa.log"
        
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(
            level=getattr(logging, self.log_level),
            format=log_format,
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        
        # LangChainãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã®è¨­å®š
        if self.langchain_tracing_v2:
            os.environ["LANGCHAIN_TRACING_V2"] = "true"
            
        # LangSmithãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã®è¨­å®š
        if self.enable_langsmith and self.langsmith_api_key:
            os.environ["LANGCHAIN_TRACING_V2"] = "true"
            os.environ["LANGCHAIN_API_KEY"] = self.langsmith_api_key
            os.environ["LANGCHAIN_PROJECT"] = self.langsmith_project
            os.environ["LANGCHAIN_ENDPOINT"] = self.langsmith_endpoint
            logger = logging.getLogger(__name__)
            logger.info(f"LangSmithè¨­å®šã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®šå®Œäº†: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ={self.langsmith_project}")
        else:
            logger = logging.getLogger(__name__)
            logger.info(f"LangSmithç„¡åŠ¹: enable_langsmith={self.enable_langsmith}, has_api_key={bool(self.langsmith_api_key)}")
    
    def get_ollama_url(self) -> str:
        """Ollamaã®URLå–å¾—"""
        return f"http://{self.ollama_host}"
    
    def ensure_directories(self) -> None:
        """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ"""
        directories = [
            self.data_dir,
            f"{self.data_dir}/chatbots",
            f"{self.data_dir}/uploads",
            self.log_dir,
            "ui/static",
            "ui/templates"
        ]
        
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
    
    def get_max_file_size_bytes(self) -> int:
        """æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚¤ãƒˆå˜ä½ã§å–å¾—"""
        return self.max_file_size_mb * 1024 * 1024
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
        case_sensitive = False
        extra = "ignore"  # å¤ã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç„¡è¦–

# ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
settings = Settings()

def get_settings() -> Settings:
    """è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®å–å¾—"""
    return settings

def setup_environment() -> Settings:
    """ç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    settings.ensure_directories()
    settings.setup_logging()
    
    logger = logging.getLogger(__name__)
    logger.info(f"ğŸš€ {settings.project_name} v{settings.version} èµ·å‹•ä¸­...")
    logger.info(f"ğŸŒ ç’°å¢ƒ: {settings.labor_qa_env}")
    logger.info(f"ğŸ¤– LLMãƒ¢ãƒ‡ãƒ«: {settings.ollama_model}")
    logger.info(f"ğŸ“ ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢: {settings.vector_store_dir}")
    logger.info(f"ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {settings.documents_dir}")
    
    return settings

# ç’°å¢ƒåˆæœŸåŒ–æ™‚ã®è‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
if __name__ == "__main__":
    setup_environment()
    print("âœ… è¨­å®šã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")